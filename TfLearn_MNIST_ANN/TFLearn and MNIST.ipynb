{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handwritten Number Recognition with TFLearn and MNIST\n",
    "\n",
    "En este notebook, construiremos una red neuronal que reconozca los números manuscritos 0-9.\n",
    "\n",
    "Este tipo de red neuronal se usa en una variedad de aplicaciones del mundo real que incluyen: reconocer números de teléfono, clasificar el correo postal por dirección, entre otros. Para construir la red, usaremos el conjunto de datos MNIST, que consiste en imágenes de números escritos a mano y sus etiquetas correspondientes a los números 0-9.\n",
    "\n",
    "Usaremos TFLearn, una biblioteca de alto nivel construida sobre TensorFlow para construir la red neuronal. Comenzaremos importando todos los módulos que necesitaremos, luego cargaremos los datos y finalmente construiremos la red.\n",
    "\n",
    "Debe tener instlado en el ambiente de trabajo, las librerias necesariias tales como TFLearn, h5py, scipy etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import Numpy, TensorFlow, TFLearn, and MNIST data\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tflearn\n",
    "import tflearn.datasets.mnist as mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Training and test data\n",
    "\n",
    "El conjunto de datos MNIST ya contiene datos de entrenamiento y de prueba. Hay 55,000 datos de entrenamiento y 10,000 datos de prueba.\n",
    "\n",
    "Cada dato MNIST tiene:\n",
    "\n",
    "- una imagen de un dígito manuscrito y\n",
    "- una etiqueta correspondiente (un número 0-9 que identifica la imagen)\n",
    "\n",
    "Llamaremos a las imágenes, que serán la entrada a nuestra red neuronal, X y sus correspondientes etiquetas Y.\n",
    "\n",
    "Vamos a querer que nuestras etiquetas sean vectores one-hot-encode, que son vectores que contienen mayormente 0 y un 1. Es más fácil ver esto en un ejemplo: Como one-hot-encode, el número 0 se representa como [1, 0, 0, 0, 0, 0, 0, 0, 0, 0] y el 4 se representa como [0, 0, 0, 0, 1, 0, 0, 0, 0, 0].\n",
    "\n",
    "\n",
    "## Aplanamiento de datos (Flattened Data)\n",
    "\n",
    "Para este ejemplo, usaremos datos aplanados o una representación de imágenes MNIST en una dimensión en lugar de dos. Por lo tanto, cada imagen de número manuscrita, que es de 28x28 píxeles, se representará como una matriz unidimensional de valores de 784 píxeles.\n",
    "\n",
    "Al aplanar los datos, se desecha la información sobre la estructura 2D de la imagen, pero simplifica nuestros datos para que los correspondientes a entrenamiento puedan estar contenidos en una matriz cuya forma es [55000, 784]; la primera dimensión es el número de imágenes de entrenamiento y la segunda dimensión es el número de píxeles en cada imagen. Este es el tipo de datos que es más fácil de analizar utilizando una red neuronal simple.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mnist/train-images-idx3-ubyte.gz\n",
      "Extracting mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the training and test data\n",
    "trainX, trainY, testX, testY = mnist.load_data(one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the training data\n",
    "\n",
    "A continuación se proporciona una función que ayudará a visualizar los datos del MNIST. Al pasar el índice de un ejemplo de entrenamiento, la función show_digit mostrará esa imagen de entrenamiento junto con su etiqueta correspondiente en el título.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEICAYAAACQ6CLfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizing the data\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Function for displaying a training image by it's index in the MNIST set\n",
    "def show_digit(index):\n",
    "    label = trainY[index].argmax(axis=0)\n",
    "    # Reshape 784 array into 28x28 image\n",
    "    image = trainX[index].reshape([28,28])\n",
    "    plt.title('Training data, index: %d,  Label: %d' % (index, label))\n",
    "    plt.imshow(image, cmap='gray_r')\n",
    "    plt.show()\n",
    "    \n",
    "# Display the first (index 0) training image\n",
    "print(trainY[0])\n",
    "show_digit(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Building the network\n",
    "\n",
    "TFLearn permite construir la red neuronal definiendo las capas.\n",
    "\n",
    "Para este ejemplo, se debe definir:\n",
    "\n",
    "   - La capa de entrada, que le dice a la red el número de entradas que debe esperar para cada parte de los datos de MNIST.\n",
    "   - Las capas ocultas, que reconocen patrones en los datos y conectan la entrada a la capa de salida, y\n",
    "   - La capa de salida, que define cómo la red aprende y genera una etiqueta para una imagen dada.\n",
    "\n",
    "Vamos para empezar la capa de entrada; para definir la capa de entrada, definirá el tipo de datos que la red espera. Por ejemplo,\n",
    "\n",
    "    net = tflearn.input_data([None, 100])\n",
    "\n",
    "Crearía una red con 100 entradas. El número de entradas a su red debe coincidir con el tamaño de los datos. Para este ejemplo, estamos utilizando vectores largos de 784 elementos para codificar nuestros datos de entrada, por lo que necesitamos 784 unidades de entrada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding layers\n",
    "\n",
    "Para agregar nuevas capas ocultas, se usa:\n",
    "\n",
    "    net = tflearn.fully_connected (net, n_units, activación = 'ReLU')\n",
    "\n",
    "Esto agrega una capa totalmente conectada, donde cada unidad (o nodo) en la capa anterior está conectada a cada unidad en esta capa. El primer argumento net es la red que creó en la llamada tflearn.input_data, que designa la entrada a la capa oculta. Puede establecer el número de unidades en la capa con n_units y configurar la función de activación con la palabra clave de activación. Puede seguir agregando capas a su red llamando repetidamente a tflearn.fully_connected (net, n_units).\n",
    "\n",
    "Luego, para configurar el entrenamiento de la red, se usa:\n",
    "\n",
    "    net = tflearn.regression (net, optimizer = 'sgd', learning_rate = 0.1, loss = 'categorical_crossentropy')\n",
    "\n",
    "Las palabras clave:\n",
    "\n",
    "- *optimizer* establece el método de entrenamiento, por ejemplo el descenso de gradiente estocástico (SGD)\n",
    "- *learning_rate* es la tasa de aprendizaje.\n",
    "- *loss* determina cómo se calcula el error en la red. En este ejemplo, con 'categorical_crossentropy'.\n",
    "\n",
    "Finalmente, se coloca todo junto para crear el modelo con tflearn.DNN (net)\n",
    "\n",
    "La función build_model( ), armará la red utilizando TFLearn. Se puede elegir cuántas capas utilizar, cuántas unidades ocultas, etc.\n",
    "\n",
    "La capa de salida final debe tener 10 nodos de salida (uno para cada dígito 0-9). e recomienda usar una capa de activación de softmax como la capa de salida final.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the neural network\n",
    "def build_model():\n",
    "    # This resets all parameters and variables, leave this here\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    # Include the input layer, hidden layer(s), and set how you want to train the model\n",
    "    #Inputs\n",
    "    net = tflearn.input_data([None, 784])\n",
    "    \n",
    "    #Hidden layers\n",
    "    net = tflearn.fully_connected(net, 100, activation = 'ReLU')\n",
    "    \n",
    "    #Output\n",
    "    net = tflearn.fully_connected(net, 10, activation = 'softmax')\n",
    "    \n",
    "    net = tflearn.regression(net, optimizer='sgd', learning_rate=0.1, loss='categorical_crossentropy')\n",
    "    \n",
    "    # This model assumes that your network is named \"net\"    \n",
    "    model = tflearn.DNN(net)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build the model\n",
    "model = build_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the network\n",
    "\n",
    "Ahora que hemos construido la red y guardado como modelo, podemos ajustarla a los datos. Aquí usamos el método model.fit. Se pasan los datos de entrada entrenamiento trainX y los datos de salida entrenamiento trainY. \n",
    "\n",
    "A continuación, se establece validation_set = 0.1, que reserva el 10% del conjunto de datos como el conjunto de validación. También puede establecer el tamaño del batch y el número de epochz con las palabras clave batch_size y n_epoch, respectivamente.\n",
    "\n",
    "Muy pocos epochs no entrenan eficazmente su red, y demasiadas tardan mucho tiempo en ejecutarse. ¡Elegir sabiamente!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 9899  | total loss: \u001b[1m\u001b[32m0.39582\u001b[0m\u001b[0m | time: 1.674s\n",
      "| SGD | epoch: 020 | loss: 0.39582 - acc: 0.9610 -- iter: 49400/49500\n",
      "Training Step: 9900  | total loss: \u001b[1m\u001b[32m0.36857\u001b[0m\u001b[0m | time: 2.690s\n",
      "| SGD | epoch: 020 | loss: 0.36857 - acc: 0.9609 | val_loss: 0.10394 - val_acc: 0.9711 -- iter: 49500/49500\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "model.fit(trainX, trainY, validation_set=0.1, show_metric=True, batch_size=100, n_epoch=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "Una vez que haya alcanzado un buen rendimiento en el punto anterior, puede ejecutar la red con el conjunto de datos de prueba para medir su rendimiento. Recuerde, solo haga esto después de haber realizado el entrenamiento y esté satisfecho con los resultados.\n",
    "\n",
    "Un buen resultado será más del 95% de precisión. ¡Se sabe que algunos modelos simples que tienen una precisión de hasta el 99.7%!\n",
    "\n",
    "Se recomienda \"jugar\" con los hyper-parámetros.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.9748\n"
     ]
    }
   ],
   "source": [
    "# Compare the labels that our model predicts with the actual labels\n",
    "\n",
    "# Find the indices of the most confident prediction for each item. That tells us the predicted digit for that sample.\n",
    "predictions = np.array(model.predict(testX)).argmax(axis=1)\n",
    "\n",
    "# Calculate the accuracy, which is the percentage of times the predicated labels matched the actual labels\n",
    "actual = testY.argmax(axis=1)\n",
    "test_accuracy = np.mean(predictions == actual, axis=0)\n",
    "\n",
    "# Print out the result\n",
    "print(\"Test accuracy: \", test_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
