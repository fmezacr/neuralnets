{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\">MMP-6122 Reconocimiento de Patrones</span>\n",
    "\n",
    "- ### Investigacion Corta 3\n",
    "- ### Esteban Rivera\n",
    "- ### Kevin Viquez"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Demo](HorizontalRule.png \"Demo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">Bibliography</span>\n",
    "\n",
    "- Zheng, Alice. *Evaluating Machine Learning Models*. O'Reilly Media,Inc.\n",
    "- https://scikit-learn.org (API Reference)\n",
    "- https://towardsdatascience.com/metrics-to-evaluate-your-machine-learning-algorithm-f10ba6e38234\n",
    "- https://medium.com/thalus-ai/performance-metrics-for-classification-problems-in-machine-learning-part-i-b085d432082b\n",
    "- https://www.machinelearningplus.com/machine-learning/evaluation-metrics-classification-models-r/\n",
    "- https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-classification-in-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Demo](HorizontalRule.png \"Demo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\">Metricas de Clasificacion</span>\n",
    "\n",
    "- Accuracy\n",
    "- Confusion Matrix\n",
    "- Precision\n",
    "- Recall\n",
    "- F1 Score\n",
    "- ROC (Receiver Operating Curve)\n",
    "- ROC AUC (Area Under Curve)\n",
    "- Per-Class Precision\n",
    "- Logarithmic Loss\n",
    "- Brier Score\n",
    "- Jaccard Index\n",
    "\n",
    "# <span style=\"color:red\">Metricas de Regresion</span>\n",
    "\n",
    "- Max Error\n",
    "- MAE (Mean Absolute Error)\n",
    "- MSE (Mean Squared Error)\n",
    "- RMSE (Root Mean Square Error)\n",
    "- R Squared\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Demo](HorizontalRule.png \"Demo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\">Accuracy</span>\n",
    "\n",
    "## En que consiste\n",
    "\n",
    "La metrica de Accuracy mide que tan seguido el clasificador realiza una prediccion correcta. Es el radio entre el numero de predicciones correctas y el numero total de predicciones.\n",
    "\n",
    "\\begin{equation*}\n",
    "Accuracy = \\frac{Numero Predicciones Correctas}{Numero Predicciones Total}\n",
    "\\end{equation*}\n",
    "\n",
    "## Casos de uso\n",
    "\n",
    "- Proposito general en problemas de clasificacion\n",
    "- Cuando las variables en los sets de datos son balanceadas.\n",
    "\n",
    "## Ventajas\n",
    "\n",
    "La mas simple de las metricas de evaluacion.\n",
    "\n",
    "## Desafios\n",
    "\n",
    "Dependiendo del set de datos utilizado para el entrenamiento, si este no es balanceado, puede dar falsos indices de precision.\n",
    "\n",
    "No realiza distincion entre clases, las respuestas correctas para una clase o para otra clase son tratadas como iguales sin dar informacion sobre los fallos.\n",
    "\n",
    "\n",
    "## Ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import metrics library\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Imagine 2 vectors, one for the classifier prediction and one with expected values\n",
    "#              o  o  x  o  o  o  x  x  x  o\n",
    "y_predicted = [0, 1, 1, 3, 2, 3, 4, 1, 2, 5]\n",
    "y_expected  = [0, 1, 2, 3, 2, 3, 1, 4, 1, 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "Accuracy = \\frac{6}{10} = 0.6\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_expected, y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Demo](HorizontalRule.png \"Demo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\">Confusion Matrix</span>\n",
    "\n",
    "## En que consiste\n",
    "\n",
    "Como su nombre lo indica esta metrica crea una matrix como salida y describe el desempeño completo del modelo. No solo muestra los aciertos y desaciertos en las predicciones sino que nos indica en que clases y con que frecuencia.    \n",
    "\n",
    "![CFM](ConfusionMatrix.png \"CFM\")\n",
    "\n",
    "### <span style=\"color:blue\">Accuracy</span>\n",
    "La precision del modelo se puede calcular:\n",
    "\n",
    "![CFM](ConfusionMatrixModelAcc.png \"CFM\")\n",
    "\n",
    "\\begin{equation*}\n",
    "Accuracy = \\frac{True Positives + True Negatives }{True Positive + True Negative + False Positive + False Negative}\n",
    "\\end{equation*}\n",
    "\n",
    "### <span style=\"color:blue\">Precision</span>\n",
    "La precision de cada clase se puede calcular:\n",
    "\n",
    "![CFM](ConfusionMatrixClassAcc.png \"CFM\")\n",
    "\n",
    "\\begin{equation*}\n",
    "Precision = \\frac{True Positives}{True Positive + False Positive}\n",
    "\\end{equation*}\n",
    "\n",
    "### <span style=\"color:blue\">Tasa de Verdaderos Positivos (A.K.A Sensibilidad o Recall)</span>\n",
    "\n",
    "Corresponde a la proporcion de verdaderos positivos predichos con respecto a todos los positivos que hubo, incluyendo los que se fallo en predecir.\n",
    "\n",
    "![Demo](ConfusionMatrixSensibility.png \"Demo\")\n",
    "\n",
    "\\begin{equation*}\n",
    "TruePositiveRate = \\frac{TruePositives}{FalseNegatives + TruePositives}\n",
    "\\end{equation*}\n",
    "\n",
    "Sensibilidad cuantifica el porcentaje de evacion de falsos negativos. Si la sensibilidad aumenta, la especificidad disminuye.\n",
    "\n",
    "### <span style=\"color:blue\">Tasa de Verdaderos Falsos (A.K.A Especificidad)</span>\n",
    "\n",
    "Corresponde a la proporcion de verdaderos negativos predichos con respecto a todos los negativos que hubo, incluyendo los que se fallo en predecir.\n",
    "\n",
    "![Demo](ConfusionMatrixSpecificity.png \"Demo\")\n",
    "\n",
    "\\begin{equation*}\n",
    "TrueNegativeRate = \\frac{TrueNegatives}{FalsePositives + TrueNegatives}\n",
    "\\end{equation*}\n",
    "\n",
    "Especificidad cuantifica el porcentaje de evacion de falsos positivos. Si la especificidad aumenta, la sensibilidad disminuye.\n",
    "\n",
    "## Casos de uso\n",
    "\n",
    "- Clasificacion binaria\n",
    "- Clasificacion multi-clase\n",
    "- Clasificacion multi-etiqueta\n",
    "\n",
    "## Ventajas\n",
    "\n",
    "Muestra el desempeño completo del modelo y permite entender en donde estan las fallas y los aciertos.\n",
    "\n",
    "## Desafios\n",
    "\n",
    "Sacar provecho de sus resultados requiere de interpretacion y analisis adicional por parte del usuario\n",
    "\n",
    "## Ejemplo Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 0 0]\n",
      " [0 0 1]\n",
      " [1 0 2]]\n"
     ]
    }
   ],
   "source": [
    "# Import library\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_expected  = [\"cat\", \"ant\", \"cat\", \"cat\", \"ant\", \"bird\"]\n",
    "y_predicted = [\"ant\", \"ant\", \"cat\", \"cat\", \"ant\", \"cat\"]\n",
    "\n",
    "confusionMatrixResult = confusion_matrix(y_expected, y_predicted, labels=[\"ant\", \"bird\", \"cat\"])\n",
    "\n",
    "print (confusionMatrixResult)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![CFM](ConfusionMatrixExample.png \"CFM\")\n",
    "\n",
    "La precision del modelo se puede calcular usando la diagonal:\n",
    "\n",
    "\\begin{equation*}\n",
    "ModelAccuracy = \\frac{2 (ants) + 0 (birds) + 2 (cats)}{6} = 0.666\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_expected, y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tambien se puede calcular la precision en la clasificacion de cada clase usando la informacion de su fila\n",
    "\n",
    "\\begin{equation*}\n",
    "AntsPrecision = \\frac{2 (true-ants)}{2 (true-ant) + 0 (false-bird) + 0 (false-cat)} = 1\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*}\n",
    "BirdsPrecision = \\frac{0 (true-birds)}{0 (false-ant) + 0 (true-bird) + 1 (false-cat)} = 0\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*}\n",
    "CatsPrecision = \\frac{2 (true-cat)}{1 (false-ant) + 0 (false-bird) + 2 (true-cat)} = 0.666\n",
    "\\end{equation*}\n",
    "\n",
    "Estos mismos valores se pueden ver en la **diagonal** de la matrix normalizada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.         0.        ]\n",
      " [0.         0.         1.        ]\n",
      " [0.33333333 0.         0.66666667]]\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "\n",
    "confusionMatrixResult = confusionMatrixResult.astype('float') / confusionMatrixResult.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "print (confusionMatrixResult)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplos - Precision y Recall (Sensibility)\n",
    "\n",
    "Usando SciKit Learn existen APIs para calcular varias de estas metricas (precision, sensibilidad, F1, etc) rapidamente. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 1, 0],\n",
       "       [0, 0, 2],\n",
       "       [0, 1, 0]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "y_true = np.array(['cat', 'dog', 'pig', 'cat', 'dog', 'pig'])\n",
    "y_pred = np.array(['cat', 'pig', 'dog', 'cat', 'cat', 'dog'])\n",
    "\n",
    "confusion_matrix(y_pred, y_true, labels=[\"cat\", \"dog\", \"pig\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![CFM](RecallExample.png \"CFM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.66666667]), array([1.]), array([0.8]), array([2]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall_fscore_support(y_true, y_pred, average=None, labels=['cat'])\n",
    "\n",
    "# Cat Precision = tp/tp+fp  = 2/2+1 = 0.66\n",
    "# Cat Recall    = tp/tp+fn  = 2/2+0 = 1\n",
    "# Cat F_Score   = 2*P*R/P+R = 2*1*0.66/1+0.66 = 0.8 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Demo](HorizontalRule.png \"Demo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\">Per-Class Precision Average</span>\n",
    "\n",
    "## En que consiste\n",
    "\n",
    "En el ejemplo anterior de *Confusion Matrix* se encontraron 4 valores de precision\n",
    "\n",
    "| Precision                             | Valor(%) |\n",
    "| ------------------------------------- | -------- |\n",
    "| MicroPrecision (A.K.A Accuracy_Score) | 66.66    |\n",
    "| Precision Clase *Ant*                 | 100      |\n",
    "| Precision Clase *Bird*                | 0        |\n",
    "| Precision Clase *Cat*                 | 66.66    |\n",
    "\n",
    "En casos de clasificacion en donde existen multiples clases puede ser muy util calcular la *Macro Precision*, para analizar el balance en la clasificacion de las clases:\n",
    "\n",
    "\\begin{equation*}\n",
    "PerClassAccuracyAverage = \\frac{Accuracy Clase 1 + Accuracy Clase 2 + ... + Accuracy Clase N }{Numero de Clases Total}\n",
    "\\end{equation*}\n",
    "\n",
    "## Casos de uso\n",
    "\n",
    "- Clasificacion multi-clase\n",
    "\n",
    "## Ventajas\n",
    "\n",
    "Otra herramienta mas para ayudar a identificar sets de datos desbalanceados, ayuda junto con las precisiones individuales por clase a identificar cuan desbalanceado es un set de datos\n",
    "\n",
    "## Desafios\n",
    "\n",
    "Su resultado requiere de interpretacion experta porque si existen muchos ejemplos de una clase y muy pocos de otra, calcular el promedio de las podria disminuir la medida de confiabilidad de la precision de las clases individuales.\n",
    "\n",
    "## Ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         0.         0.66666667]\n"
     ]
    }
   ],
   "source": [
    "# Imports \n",
    "import numpy as np\n",
    "import statistics as s\n",
    "\n",
    "# Using the results from the previous Confusion Matrix\n",
    "AccuracyPerClass = confusionMatrixResult.diagonal()\n",
    "\n",
    "print(AccuracyPerClass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5555555555555556"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.mean(AccuracyPerClass)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El valor de macro-precision obtenido de haber promediado la precision por clase, nos muestra que hay un desbalance en el exito de las predicciones por clase\n",
    "\n",
    "| Precision                             | Valor(%) |\n",
    "| ------------------------------------- | -------- |\n",
    "| MicroPrecision (A.K.A Accuracy_Score) | 66.66    |\n",
    "| Precision Clase *Ant*                 | 100      |\n",
    "| Precision Clase *Bird*                | 0        |\n",
    "| Precision Clase *Cat*                 | 66.66    |\n",
    "| MacroPrecision                        | 55.55    |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Demo](HorizontalRule.png \"Demo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\">F1 Score</span>\n",
    "\n",
    "Realmente no deseamos andar calculando las metricas anteriores, generalmente deseammos tener un solo valor que nos indique la ambas. Para esto podemos tomar la media artimetica como base. Veamos un ejemplo, tenemos 100 transacciones bancarias, de las cuales 97 son legitimas y 3 son fraudes. Asumamos que teniamos un modelo que predijo todo como un fraude:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Predicted \\ Actual  | Fraud | Not Fraud |\n",
    "| --- | --- | --- |\n",
    "| __Fraud__ | 3 | 97 |\n",
    "| __Not Fraud__ | 0 | 0 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizando las metricas de precision y Sensibilidad, obtenemos: \n",
    "\n",
    "\\begin{equation*}\n",
    "Precision = \\frac{3}{100} = 3 \\%\n",
    "\\end{equation*}\n",
    "\n",
    "\n",
    "\\begin{equation*}\n",
    "Sensibilidad = \\frac{3}{3} = 100 \\%\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora con la media aritmética tenemos que arroja el valor de 51%. Dicho valor no tiene sentido para el modelo planteado que predijo que todo era un fraude. \n",
    "Necesitamos un modelo mas robusto y mejor balanceado que la media aritmetica. La media harmonica viene a cumplir un papel en esta metrica. \n",
    "\n",
    "\\begin{equation*}\n",
    "Media Harmonica = \\frac{2 * x * y}{x + y}\n",
    "\\end{equation*}\n",
    "\n",
    "\n",
    "La media armónica es casi un promnedio cuando los valores x, y, son iguales. Por otro lado, la media harmonica se aproxima al valor menor cuando x, y son diferentes.\n",
    "\n",
    "Aplicando la media harmónica al ejemplo anterior,  con P como precisión y R como Recall(Sensibilidad), obtenemos:\n",
    "\n",
    "\n",
    "\\begin{equation*}\n",
    "F1 Score = \\frac{2 * P * R}{P + R}\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*}\n",
    "F1 Score = \\frac{2 * 3 * 100}{3 + 100}\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*}\n",
    "F1 Score = 5.8\\%\n",
    "\\end{equation*}\n",
    "\n",
    "\n",
    "El resultado obtenido es pequeño por lo tanto da una señal de que uno de los valores también es muy pequeño, siendo un valor más realista que describe el modelo utilizado. \n",
    "\n",
    "\n",
    "## Casos de Uso\n",
    "\n",
    "Generalmente es utilizado con la métricas de Precisión y Sensibilidad.\n",
    "\n",
    "\n",
    "## Ventajas \n",
    "\n",
    "- Genera un solo valor que da un señal de cómo está el modelo en cuanto la precisión y sensibilidad.\n",
    "\n",
    "\n",
    "## Desafios\n",
    "\n",
    "- Trata todos los datos obtenidos equitativamente. Es decir, un resultado en la posición k es igual de importante que un resultado en la posicion l.\n",
    "\n",
    "## Ejemplos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26666666666666666"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "y_true = [0, 1, 2, 0, 1, 2]\n",
    "y_pred = [0, 2, 1, 0, 0, 1]\n",
    "f1_score(y_true, y_pred, average='macro')  \n",
    "#0.26..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_true, y_pred, average='micro')  \n",
    "#0.33..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26666666666666666"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_true, y_pred, average='weighted')  \n",
    "#0.26..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.8, 0. , 0. ])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_true, y_pred, average=None)\n",
    "#array([0.8, 0. , 0. ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Demo](HorizontalRule.png \"Demo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\">ROC (Receiver Operating Curve) and its AUC (Area Under the Curve)</span>\n",
    "\n",
    "## En que consiste\n",
    "\n",
    "Ampliamente utilizado en problemas de clasificacion binaria. Los ROC son graficas que muestran la relacion de la sensibilidad y la especifidad de un modelo, cada par ordenado se puede extraer de la matriz de confusion obtenida despues de entrenar y poner a prueba a un modelo de clasificacion.\n",
    "\n",
    "El ROC permite de manera grafica evaluar la eficacia de un clasificador binario al plotear los resultados de sus diferentes iteraciones en una sola curva.\n",
    "\n",
    "![Demo](ROCPlotPoint.png \"Demo\")\n",
    "\n",
    "Tiene dos funciones principales:\n",
    "\n",
    "Primero, permite comparar resultados de desempeño de un modelo cuando se varian las probabilidades numericas de los limites de desicion\n",
    "\n",
    "![Demo](ROC.png \"Demo\")\n",
    "\n",
    "Segundo, el Area bajo la curva es un cuantificador de cuan bueno es un modelo, su valor maximo es **1** y se puede utilizar para comparar desempeño entre modelos de clasificadores\n",
    "\n",
    "![Demo](ROC_AUC.png \"Demo\")\n",
    "\n",
    "## Casos de uso\n",
    "\n",
    "- Clasificacion binaria\n",
    "- Clasificacion multi-etiqueta\n",
    "\n",
    "## Ventajas\n",
    "\n",
    "Resume en una grafica el comportamiento del modelo ante variaciones de sus hiperparametros para que el usuario decida cuales son los valores optimos para resolver su problema\n",
    "\n",
    "## Desafios\n",
    "\n",
    "- Requiere de interpretacion experta\n",
    "- Es laborioso crear las curvas\n",
    "\n",
    "## Ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# Generate 2 class dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_classes=2, weights=[1,1], random_state=1)\n",
    "# Split into train/test sets\n",
    "trainX, testX, trainy, testy = train_test_split(X, y, test_size=0.5, random_state=2)\n",
    "\n",
    "# Fit a model\n",
    "model = KNeighborsClassifier(n_neighbors=3)\n",
    "model.fit(trainX, trainy)\n",
    "# Predict probabilities\n",
    "probs = model.predict_proba(testX)\n",
    "# Keep probabilities for the positive outcome only\n",
    "probs = probs[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se toman las probabilidades numericas de las predicciones del clasificador para usarlas como valores de umbral de prueba y ver como cambiaria el comportamiento del modelo si fueran utilizadas como el criterio de decision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.895\n",
      "\n",
      "Thresholds\n",
      "['2.000%', '1.000%', '0.667%', '0.333%', '0.000%']\n",
      "\n",
      "True Positive Rate\n",
      "['0.000%', '0.562%', '0.884%', '0.975%', '1.000%']\n",
      "False Positive Rate\n",
      "['0.000%', '0.054%', '0.217%', '0.407%', '1.000%']\n"
     ]
    }
   ],
   "source": [
    "# Calculate AUC\n",
    "auc = roc_auc_score(testy, probs)\n",
    "print('AUC: %.3f' % auc)\n",
    "\n",
    "# Calculate roc curve points\n",
    "fpr, tpr, thresholds = roc_curve(testy, probs)\n",
    "\n",
    "# Print the threshould we are going to be testing with ROC\n",
    "print (\"\\nThresholds\")\n",
    "print(list(map('{:.3f}%'.format,thresholds)))\n",
    "\n",
    "# Print the (x,y) coordinates of the data points\n",
    "print (\"\\nTrue Positive Rate\")\n",
    "print(list(map('{:.3f}%'.format,tpr)))\n",
    "\n",
    "print (\"False Positive Rate\")\n",
    "print(list(map('{:.3f}%'.format,fpr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot\n",
    "pyplot.plot([0, 1], [0, 1], linestyle='--')\n",
    "# Plot the roc curve for the model\n",
    "pyplot.plot(fpr, tpr, marker='.')\n",
    "# Show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de este punto se requiere de interpretacion por parte del usuario para decidir cuantos falsos positivos se puede permitir para el problema en analisis.\n",
    "\n",
    "Por ejemplo:\n",
    "- Si se usa un umbral de decision de 66% en la clasificacion, se obtendran un 88.4% de Verdaderos Positivos pero un 21.7% de Falsos Positivos\n",
    "- Si se usa un umbral de decision de 33% en la clasificacion, se obtendran un 97.5% de Verdaderos Positivos pero un 40.7% de Falsos Positivos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Demo](HorizontalRule.png \"Demo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\">Logarithmic Loss</span>\n",
    "\n",
    "## En que consiste\n",
    "\n",
    "Analiza la salida cruda de un clasificador cuando su salida es una probabilidad numerica en lugar de una variable booleana. Esta probabilidad se puede usar como un indice de confiabilidad.\n",
    "\n",
    "La clasificacion boleana (0 ó 1) se puede ver en terminos numeros como probabilidad por arriba y por debajo de 0.50, siendo clase 0 si el valor es igual o menor que 0.50, y clase 1 si el valor es mayor o igual que 0.51.\n",
    "\n",
    "El analisis logaritmo analiza los fallos y aciertos en terminos de estas probabilidades numericas para ver que tan contundentes son los aciertos y los desaciertos. Valores cercanos a 0.50 tienen la probabilidad de ser clasificados como cualquiera de las dos clases, lo ideal es lograr resultados tan cerca de los extremos (0 ó 1) como sea posible.\n",
    "\n",
    "Matematicamente para un clasificador binario se define como:\n",
    "\n",
    "\\begin{equation*}\n",
    "LogLoss = \\frac{-1}{N} \\sum_{i=1}^N y_i \\times log p_i + (1-y_i) \\times log(1-p_i)\n",
    "\\end{equation*}\n",
    "\n",
    "*Logarithmic Loss* es la entropia cruzada entre las distribuciones de valores esperados y de predicciones, la entropia mide la inprevisibilidad de algo, en este caso, mide el \"ruido\" que provoca el modelo predictor y que causa que el vector de salidas del predictor no sea igual al vector de valores esperados.\n",
    "\n",
    "Minimizar ese \"ruido\" es equivalente a mejorar el desempeño del modelo de prediccion.\n",
    "\n",
    "## Casos de uso\n",
    "\n",
    "- Clasificacion multi-etiqueta\n",
    "- Clasificacion multi-clase\n",
    "- Cuando la salida de un algoritmo clasificador es una probabilidad numerica en lugar de una variable booleana\n",
    "\n",
    "## Ventajas\n",
    "\n",
    "Un metrica de evaluacion mas meticulosa que accuracy_score y que busca no solo analizar las predicciones correctas, sino tambien cuantificar cuan cerca o lejos estuvieron del limite de decision\n",
    "\n",
    "## Desafios\n",
    "\n",
    "Trabajar con escala logaritmica no es intuitivo\n",
    "\n",
    "## Ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1094237467877998e-15"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imports\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "# Perfect prediction\n",
    "actual_labels = [\"ant\", \"bird\", \"cat\"]\n",
    "log_loss(actual_labels,  [[1, 0, 0], [0, 1, 0], [0, 0, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34.538776394910684"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Completely wrong prediction in all 3 cases\n",
    "log_loss(actual_labels,  [[0, 0, 1], [0, 0, 1], [1, 0, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.639107564067801"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction with non binary probabilities\n",
    "log_loss(actual_labels,  [[0.35, 0.65, 0], [0, 0.70, 0.30], [0.2, 0.2, 0.6]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo con Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy = 0.78\n",
      "Log-Loss = 1.289\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "# Generate data\n",
    "X, y = make_blobs(n_samples=1000, n_features=2, random_state=42, cluster_std=5.0)\n",
    "\n",
    "# Divide the data in training-set and testing-set\n",
    "X_train, y_train = X[:800], y[:800]\n",
    "X_test, y_test = X[800:], y[800:]\n",
    "\n",
    "# Train uncalibrated random forest classifier on whole train and validation\n",
    "# data and evaluate on test data\n",
    "clf = RandomForestClassifier(n_estimators=25)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Get predictions and predictions probabilities\n",
    "y_predict = clf.predict(X_test)\n",
    "y_predict_probability = clf.predict_proba(X_test)\n",
    "\n",
    "# Get the accuracy and logaritmic loss metrics\n",
    "accuracy_score = accuracy_score(y_test, y_predict)\n",
    "logloss_score = log_loss(y_test, y_predict_probability)\n",
    "\n",
    "print(\"Test accuracy = {}\".format(accuracy_score))\n",
    "print(\"Log-Loss = {:0.3f}\".format(logloss_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Demo](HorizontalRule.png \"Demo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\">Brier Score</span>\n",
    "\n",
    "## En que consiste\n",
    "\n",
    "Se suele interpretar como una medida de la \"calibration\" de un set de predicciones probabilisticas, o como una funcion de costo. La metrica de Brier mide la diferencia media cuadratica entre:\n",
    "\n",
    "- La probabilidad predicha para el item *i*\n",
    "- El valor actual del item *i*\n",
    "\n",
    "\\begin{equation*}\n",
    "Brier Score = \\frac{1}{N} \\sum_{t=1}^N (f_t-o_t)^2\n",
    "\\end{equation*}\n",
    "\n",
    "Su valor se encuentra en 0 y 1, siendo 0 el mejor resultado y 1 el peor.\n",
    "\n",
    "## Casos de uso\n",
    "\n",
    "- En clasificacion binaria\n",
    "- Prediccion es una probabilidad numerica\n",
    "\n",
    "## Ventajas\n",
    "\n",
    "Mide el desempeño como si fuera una funcion de costo, sumando error por cada prediccion\n",
    "\n",
    "## Desafios\n",
    "\n",
    "No es apropiado cuando ocurren eventos con baja o alta frecuencia porque no puede discriminar los cambios en la prediccion que son significantes\n",
    "\n",
    "## Ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03749999999999999"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import brier_score_loss\n",
    "\n",
    "y_prob = np.array([0.1, 0.9, 0.8, 0.3])\n",
    "y_true = np.array([0, 1, 1, 0])\n",
    "\n",
    "# How to calculate Brier score manually\n",
    "# - We expected not to rain (P=0.1) and it didn't rain (0) = (0.1-0)^2\n",
    "# - We expected rain (P=0.9) and it rained (1)             = (0.9-1)^2\n",
    "# - We expected rain (P=0.8) and it rained (1)             = (0.8-1)^2\n",
    "# - We expected not to rain (P=0.3) and it didn't rain (0) = (0.3-0)^2\n",
    "\n",
    "# Now we apply the formula\n",
    "# ((0.1-0)^2 + (0.9-1)^2 + (0.8-1)^2 + (0.3-0)^2) / 4\n",
    "# (0.01 + 0.01 + 0.04 + 0.09) /4 = 0.0375\n",
    "\n",
    "brier_score_loss(y_true, y_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Demo](HorizontalRule.png \"Demo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\">Jaccard Score</span>\n",
    "\n",
    "## En que consiste\n",
    "\n",
    "Es una estadistica utilizada para medir la similaridad y diversidad de sets de muestras. Se define como la division de la interseccion de los grupos entre su union.\n",
    "\n",
    "\\begin{equation*}\n",
    "Jaccard Index = \\frac{A \\bigcap B}{A \\bigcup B}\n",
    "\\end{equation*}\n",
    "\n",
    "Su valor se encuentra en 0 y 1, siendo 1 el mejor resultado y 0 el peor.\n",
    "\n",
    "## Casos de uso\n",
    "\n",
    "- Clasificacion multi-etiqueta\n",
    "- Comparacion entre grupos de datos\n",
    "\n",
    "## Ventajas\n",
    "\n",
    "Mide similitud entre datos\n",
    "\n",
    "## Desafios\n",
    "\n",
    "La similitud entre los grupos de datos dice poco de como mejorar la configuracion del modelo de clasificacion\n",
    "\n",
    "## Ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def jaccard_similarity(list1, list2):\n",
    "    s1 = set(list1)\n",
    "    s2 = set(list2)\n",
    "    return len(s1.intersection(s2)) / len(s1.union(s2))\n",
    "\n",
    "list1 = [0,1,2,5,6,0,1]\n",
    "list2 = [0,2,3,4,5,7,9]\n",
    "\n",
    "# Jaccard measures how similar are 2 groups by dividing their intersection by their union\n",
    "# J(A,B) = |A∩B| / |A∪B| \n",
    "#        = |{0,2,5}| / |{0,1,2,3,4,5,6,7,9}| \n",
    "#        = 3/9 = 0.33\n",
    "\n",
    "jaccard_similarity(list1, list2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Demo](HorizontalRule.png \"Demo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\">Resumen de Metricas para Clasificacion</span>\n",
    "\n",
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-spacing:0;}\n",
    ".tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:black;}\n",
    ".tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:black;}\n",
    ".tg .tg-0pky{border-color:inherit;text-align:left;vertical-align:top}\n",
    "</style>\n",
    "<table class=\"tg\">\n",
    "  <tr>\n",
    "    <th class=\"tg-0pky\">Metrica</th>\n",
    "    <th class=\"tg-0pky\">Caso de Uso</th>\n",
    "    <th class=\"tg-0pky\">Ventaja</th>\n",
    "    <th class=\"tg-0pky\">Desafio</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky\" align=\"right\">Accuracy Score</td>\n",
    "    <td class=\"tg-0pky\" align=\"right\">- Proposito general</td>\n",
    "    <td class=\"tg-0pky\" align=\"right\">- Simplicidad</td>\n",
    "    <td class=\"tg-0pky\" align=\"right\">- No distingue entre clases<br>- No muestra informacion sobre fallas</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky\" align=\"right\">Confusion Matrix</td>\n",
    "    <td class=\"tg-0pky\" align=\"right\">- Clasificacion binaria<br>- Clasificacion multi-clase<br>- Clasificacion multi-etiqueta</td>\n",
    "    <td class=\"tg-0pky\" align=\"right\">- Muestra desglose de aciertos y fallas<br>- Base para calcular muchas otras metricas</td>\n",
    "    <td class=\"tg-0pky\" align=\"right\">- Para sacarle provecho a los resultados requiere de analisis adicional por parte del usuario</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky\" align=\"right\">Presicion-Sensitividad</td>\n",
    "    <td class=\"tg-0pky\" align=\"right\">- Clasificacion binaria<br>-Clasificacion multi-etiqueta</td>\n",
    "    <td class=\"tg-0pky\" align=\"right\">- Simplicidad</td>\n",
    "    <td class=\"tg-0pky\" align=\"right\">- Uno afecta al otro<br>- No es facil de optimizar si no hay objetivos claros<br>- Base para calcular muchas otras metricas</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky\" align=\"right\">F1 Score</td>\n",
    "    <td class=\"tg-0pky\" align=\"right\">-Clasificacion multi-etiqueta<br>- Clasificacion multi-clase</td>\n",
    "    <td class=\"tg-0pky\" align=\"right\">- Genera una sola salida para la precision y la sensitividad.</td>\n",
    "    <td class=\"tg-0pky\" align=\"right\">Para sacarle provecho a los resultados requiere de analisis adicional por parte del usuario</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky\" align=\"right\">Per-Class Precision Average</td>\n",
    "    <td class=\"tg-0pky\" align=\"right\">- Clasificacion multi-clase</td>\n",
    "    <td class=\"tg-0pky\" align=\"right\">- Ayuda a cuantificar si los datos de entrenamiento son parciales hacia una clase</td>\n",
    "    <td class=\"tg-0pky\" align=\"right\">- Calcular el promedio de las clases puede disminuir la medida de confiabilidad de la precision de las clases individuales</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky\" align=\"right\">ROC</td>\n",
    "    <td class=\"tg-0pky\" align=\"right\">- Clasificacion binaria<br>- Comparacion grafica de desempeño</td>\n",
    "    <td class=\"tg-0pky\" align=\"right\">- Comparacion visual de los efectos de multiples configuraciones</td>\n",
    "    <td class=\"tg-0pky\" align=\"right\">- Generar curvas ROC es laborioso</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky\" align=\"right\">ROC_AUC</td>\n",
    "    <td class=\"tg-0pky\" align=\"right\">- Comparacion cuantitativa de curvas ROC</td>\n",
    "    <td class=\"tg-0pky\" align=\"right\">- Cuantificador de desempeño de diferentes modelos</td>\n",
    "    <td class=\"tg-0pky\" align=\"right\">- Requiere de curvas ROC</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky\" align=\"right\">Log Loss</td>\n",
    "    <td class=\"tg-0pky\" align=\"right\">- Clasificacion multi-etiqueta<br>- Salida es una probabilidad numerica<br>- Analisis de cuan alejadas estan las predicciones del limite de decision </td>\n",
    "    <td class=\"tg-0pky\" align=\"right\">- Para optimizar valores mas alla del limite de decision del clasificador</td>\n",
    "    <td class=\"tg-0pky\" align=\"right\">- Trabajar en escala logaritmica no es intuitivo</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky\" align=\"right\">Brier Score</td>\n",
    "    <td class=\"tg-0pky\" align=\"right\">- Clasificacion binaria<br>- Salida es una probabilidad numerica</td>\n",
    "    <td class=\"tg-0pky\" align=\"right\">- Mide el desempeño como si fuera una funcion de costo</td>\n",
    "    <td class=\"tg-0pky\" align=\"right\">- No es apropiado cuando ocurren eventos con baja o alta frecuencia</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky\" align=\"right\">Jaccard Index</td>\n",
    "    <td class=\"tg-0pky\" align=\"right\">- Clasificacion multi-etiqueta<br>- Comparacion entre grupos de datos</td>\n",
    "    <td class=\"tg-0pky\" align=\"right\">- Mide similitud entre datos</td>\n",
    "    <td class=\"tg-0pky\" align=\"right\">- La similitud entre los grupos de datos dice poco de como mejorar la configuracion del modelo de clasificacion</td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Demo](HorizontalRule.png \"Demo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\">Max Error</span>\n",
    "\n",
    "Calcula el máximo error residual del modelo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Casos de Uso\n",
    "\n",
    "Se desea encontrar el error maximo\n",
    "\n",
    "## Ventajas\n",
    "\n",
    "Simplicidad\n",
    "\n",
    "## Desafios\n",
    "\n",
    "Ninguno\n",
    "\n",
    "## Ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1799999999999997"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import max_error\n",
    "y_true = [3, 2, 7, 1]\n",
    "y_pred = [4.18, 2, 7, 1]\n",
    "max_error(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Demo](HorizontalRule.png \"Demo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\">MAE (Mean Absolute Error)</span>\n",
    "\n",
    "\n",
    "Es la diferencia entre los valores originales y los valores predichos. Nos da promedio de que tan largo estan los valores actuales obtenidos de los predichos. \n",
    "\n",
    "\\begin{equation*}\n",
    "MAE = \\frac{ \\sum_{i=1}^n |y_i-\\bar{y_i}|}{n}\n",
    "\\end{equation*}\n",
    "\n",
    "## Casos de Uso\n",
    "\n",
    "- Problemas de Regresion\n",
    "- Escala Lineal para todos los errores\n",
    "- Si existen outliers que no son de interes\n",
    "\n",
    "## Ventajas\n",
    "\n",
    "- Todos los errores mantienen su diferencia lineal, es decir no existe escalamiento como en el caso de RMSE\n",
    "\n",
    "## Desafios\n",
    "\n",
    "- No es tan sensible a outliers\n",
    "\n",
    "## Ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "y_true = [3, -0.5, 2, 7]\n",
    "y_pred = [2.5, 0.0, 2, 8]\n",
    "mean_absolute_error(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = [[0.5, 1], [-1, 1], [7, -6]]\n",
    "y_pred = [[0, 2], [-1, 2], [8, -5]]\n",
    "mean_absolute_error(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5, 1. ])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_true, y_pred, multioutput='raw_values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_true, y_pred, multioutput=[0.3, 0.7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Demo](HorizontalRule.png \"Demo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\">MSE (Mean Squared Error)</span>\n",
    "\n",
    "Es muy similar a MAE con la diferencia de que se calcula el cuadraro de la resta entre los valores originales y los valores predichos. \n",
    "\n",
    "\\begin{equation*}\n",
    "MSE = \\frac{ \\sum_{i=1}^n (y_i-\\bar{y_i})^2}{n}\n",
    "\\end{equation*}\n",
    "\n",
    "## Casos de Uso\n",
    "\n",
    "- Problemas de Regression\n",
    "- Los errores son mayores que 1\n",
    "- Existen outliers de interes\n",
    "\n",
    "## Ventajas \n",
    "\n",
    "- Es útil cuando tenemos valores inesperados que son de importancia. \n",
    "\n",
    "## Desafios\n",
    "\n",
    "- Si se comete un error en la predicción, al elevar al cuadrado hace más grande el error, provocando que una sobre estimación del modelo. \n",
    "- Por otro lado, si los errores son pequeños o menores a 1 se desestima el modelo.\n",
    "- No es recomendado cuando los datos tienen mucho ruido\n",
    "\n",
    "## Ejemplos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.375"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "y_true = [3, -0.5, 2, 7]\n",
    "y_pred = [2.5, 0.0, 2, 8]\n",
    "mean_squared_error(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7083333333333334"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = [[0.5, 1],[-1, 1],[7, -6]]\n",
    "y_pred = [[0, 2],[-1, 2],[8, -5]]\n",
    "mean_squared_error(y_true, y_pred)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.41666667, 1.        ])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_true, y_pred, multioutput='raw_values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.825"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_true, y_pred, multioutput=[0.3, 0.7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Demo](HorizontalRule.png \"Demo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\">RMSE (Root Mean Square Error)</span>\n",
    "\n",
    "## En que consiste\n",
    "\n",
    "Es la metrica mas comunmente utilizada para analisis de regression, tambien se le conoce como RMSD (root mean square deviation). Se define como la raiz cuadrada del promedio al cuadrado de la distancia entre el valor actual y el valor predicho:\n",
    "\n",
    "\\begin{equation*}\n",
    "RMSE = \\sqrt{ \\frac{ \\sum_{i=1}^n (y_i-\\bar{y_i})^2}{n} }\n",
    "\\end{equation*}\n",
    "\n",
    "El objetivo es minimizarlo, un valor de \"0\" indica que no hay error.\n",
    "\n",
    "## Casos de uso\n",
    "\n",
    "- Regression\n",
    "- Errores son mayores que 1\n",
    "- Existen outliers de interes\n",
    "\n",
    "## Ventajas\n",
    "\n",
    "Introduce una raiz para mejorar su respuesta ante errores con valores altos, escalandolos\n",
    "\n",
    "## Desafios\n",
    "\n",
    "- Mas complejo de utilizar que MSE\n",
    "- Si se comete un error en la predicción, al elevar al cuadrado hace más grande el error, provocando que una sobre estimación del modelo. \n",
    "- Por otro lado, si los errores son pequeños o menores a 1 se desestima el modelo.\n",
    "- No es recomendado cuando los datos tienen mucho ruido\n",
    "\n",
    "## Ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "# Perfect prediction, 0 error\n",
    "y_expected = [2.5, -0.5, 2, 7]\n",
    "y_predicted = [2.5, -0.5, 2, 7]\n",
    "sqrt(mean_squared_error(y_expected, y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6123724356957945"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction with error\n",
    "y_expected = [3, -0.5, 2, 7]\n",
    "y_predicted = [2.5, 0.0, 2, 8]\n",
    "sqrt(mean_squared_error(y_expected, y_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Demo](HorizontalRule.png \"Demo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\">R Squared</span>\n",
    "\n",
    "Es una metrica que indica que tan bueno es el modelo con respecto a set de datos que se tiene. El valor puede estar entre 0 y 1 o en su defecto puede ser negativo. Un valor de R cuadrado negativo indica que el modelo no es tan bueno en comparacion con el MSE.\n",
    "\n",
    "Las fórmulas generales son: \n",
    "\n",
    "\\begin{equation*}\n",
    "R^2 = 1 - \\frac{MSE (RL)}{MSE (Prom)}\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*}\n",
    "R^2 = 1 - \\frac{MSE (Model)}{MSE (Baseline)}\n",
    "\\end{equation*}\n",
    "\n",
    "Donde MSE (RL) es el error cuadratico medio con respecto a la regresión lineal y el MSE (Prom) es el error cuadrático medio con respecto a el promedio. \n",
    "\n",
    "## Casos de Uso\n",
    "\n",
    "Extension del metrica MSE\n",
    "\n",
    "## Ventajas\n",
    "\n",
    "- Tiene la ventaja de ser una metrica libre de escala. No importa si los valores son grandes o pequenos, dado que el valor de R\\^2 siempre estara entre menos infinito y 1.  \n",
    "\n",
    "## Desafios\n",
    "\n",
    "- Extension de MSE\n",
    "\n",
    "## Ejemplos\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9486081370449679"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# El modelo predice algunos valores y otros son muy cercanos. Un R2 cercano a 1.\n",
    "y_true = [3, -0.5, 2, 7]\n",
    "y_pred = [2.5, 0.0, 2, 8]\n",
    "r2_score(y_true, y_pred)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9382566585956417"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# El modelo define pesos basados en la varianza de cada dato por separado. Un R2 cercano a 1.\n",
    "y_true = [[0.5, 1], [-1, 1], [7, -6]]\n",
    "y_pred = [[0, 2], [-1, 2], [8, -5]]\n",
    "r2_score(y_true, y_pred,multioutput='variance_weighted') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# El modelo predice perfectamente el original, por lo tanto el R2 es 1 o cercano.\n",
    "y_true = [1, 2, 3]\n",
    "y_pred = [1, 2, 3]\n",
    "r2_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# El modelo predice algunos elementos y otros no. Por tanto el R2 es 0 o cercano. \n",
    "y_true = [1, 2, 3]\n",
    "y_pred = [2, 2, 2]\n",
    "r2_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# El modelo predicho no coincide con el original, esto implica un R2 negativo\n",
    "y_true = [1, 2, 3]\n",
    "y_pred = [3, 2, 1]\n",
    "r2_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Demo](HorizontalRule.png \"Demo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\">Resumen de Metricas para Regresion</span>\n",
    "\n",
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-spacing:0;}\n",
    ".tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:black;}\n",
    ".tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:black;}\n",
    ".tg .tg-0pky{border-color:inherit;text-align:left;vertical-align:top}\n",
    "</style>\n",
    "<table class=\"tg\">\n",
    "  <tr>\n",
    "    <th class=\"tg-0pky\">Metrica</th>\n",
    "    <th class=\"tg-0pky\">Caso de Uso</th>\n",
    "    <th class=\"tg-0pky\">Ventaja</th>\n",
    "    <th class=\"tg-0pky\">Desafio</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky\" align=\"right\">Max Error</td>\n",
    "    <td class=\"tg-0pky\" align=\"right\">- Encontrar el error maximo</td>\n",
    "    <td class=\"tg-0pky\" align=\"right\">- Simplicidad</td>\n",
    "    <td class=\"tg-0pky\" align=\"right\"></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky\" align=\"right\">MAE</td>\n",
    "    <td class=\"tg-0pky\" align=\"right\">- Problemas de Regresion<br>- Escala lineal<br>- Si existen outliers que no son importantes</td>\n",
    "    <td class=\"tg-0pky\" align=\"right\">- Todos los errores mantienen su diferencia lineal, es decir no existe escalamiento como en el caso de RSME</td>\n",
    "    <td class=\"tg-0pky\" align=\"right\">- No es tan sensible a outliners, si estos son de interes evitar esta metrica</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky\" align=\"right\">MSE</td>\n",
    "    <td class=\"tg-0pky\" align=\"right\">- Problemas de Regresion<br>- Errores son mayores que 1<br>- Existen outliers de interes</td>\n",
    "    <td class=\"tg-0pky\" align=\"right\">- Util si existen valores inesperados de interes</td>\n",
    "    <td class=\"tg-0pky\" align=\"right\">- Sensible a malas predicciones con valores altos (que se elevan al cuadrado)<br>- No es recomendado cuando los datos son ruidosos<br>- Si los erroes son menores que 1, el MSE sera bajo y se puede sobreestimar cuan malo es el modelo</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky\" align=\"right\">RMSE</td>\n",
    "    <td class=\"tg-0pky\" align=\"right\">- Problemas de Regresion<br>- Errores son mayores que 1<br>- Existen outliers de interes</td>\n",
    "    <td class=\"tg-0pky\" align=\"right\">- Introduce una raiz cuadrada para mejorar su respuesta antes errores con valores altos, escalandolos</td>\n",
    "    <td class=\"tg-0pky\" align=\"right\">- Mas complejo que utilizar MSE<br>- Si los erroes son menores que 1, el RMSE sera bajo y se puede sobreestimar cuan malo es el modelo</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky\" align=\"right\">R Squared</td>\n",
    "    <td class=\"tg-0pky\" align=\"right\">- Cuando se trabaja con MSE<br>- Comparacion de modelos contra modelo base</td>\n",
    "    <td class=\"tg-0pky\" align=\"right\">- Extension de la metrica MSE<br>- Metrica libre de escala, su valor siempre estara entre infinito negativo y 1</td>\n",
    "    <td class=\"tg-0pky\" align=\"right\">- Extension de MSE</td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
